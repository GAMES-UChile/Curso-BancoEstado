{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso BancoEstado-CMM: Aprendizaje de Máquinas Avanzado \n",
    "**Autores:** Taco de Wolff y Felipe Tobar  \n",
    "\n",
    "**Fecha:** 30 octubre, 2019\n",
    "\n",
    "\n",
    "# Módulo 5 - Modelos paramétricos y redes neuronales usando PyTorch\n",
    "**Contenidos**\n",
    "- ¿Qué es PyTorch y cómo se compara con NumPy?\n",
    "- Construir y entrenar una Red Neuronal\n",
    "\n",
    "## Introducción\n",
    "PyTorch es una librería basado en Python para computaciones escientíficas con el objetivo de reemplazar NumPy para utilizar el poder de GPU, y proveer una media de investigaciones aprendizaje profunda con velocidad y flexibilidad. También existe TensorFlow que proviene más o menos lo mismo, pero una de las principales diferencias entre TensorFlow y PyTorch es que TensorFlow genera grafos estaticos, que deben ser construidos por completo antes de evaluarlos, en cambio PyTorch presenta grafos dinámicos, pueden ser modificados y evaluados por nodo.\n",
    "\n",
    "Características de PyTorch:\n",
    "* Permite trabajo en tensores, similares a NumPy array pero permitiendo operaciones en la GPU.\n",
    "* Diferenciación automática para construir y entrenar modelos, en particular redes neuronales.\n",
    "* La gran diferencia con usar NumPy es que PyTorch (al igual que TensorFlow) construyen un grafo de computación, que luego es alimentado con los valores.\n",
    "\n",
    "Instalar con `conda install pytorch torchvision cpuonly -c pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "Un tensor de PyTorch es similar al `ndarray` de NumPy. Exploremos que son tensores con código. Podemos alocar un tensor sin initializar sus valores con `torch.empty(shape)`. Esta nos da un tensor con valores que estaban en el memoria antes y es necesario initializar todos valores nosostros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También existen funciones que initializan los valores automaticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con valores aleatoreas entre `0` y `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2407, 0.4107, 0.3400],\n",
       "        [0.9043, 0.4654, 0.8055],\n",
       "        [0.9965, 0.9968, 0.9355],\n",
       "        [0.4720, 0.7296, 0.7709],\n",
       "        [0.1129, 0.5934, 0.5383]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O con desde un areglo de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[5.5, 9, 3], [9.9, 0.2, 3]])\n",
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conección con NumPy\n",
    "Al fondo PyTorch y NumPy usan los mismos datos. Cambiar desde NumPy hasta PyTorch no duplica los datos, refieren a los mismos datos. Es decir que cambiar los datos en uno afectan los valores en el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un areglo en NumPy, convertímoslo hasta PyTorch. Después cambiamos un valor en NumPy y veamos el cambio en PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([  1.,   1.,   1., 100.,   1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np_areglo = np.ones(5)\n",
    "pt_tensor = torch.from_numpy(np_areglo)\n",
    "\n",
    "print(pt_tensor)\n",
    "\n",
    "np_areglo[3] = 100\n",
    "\n",
    "print(pt_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también el revés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[  1.   1.   1. 100.   1.]\n"
     ]
    }
   ],
   "source": [
    "pt_tensor = torch.ones(5)\n",
    "np_areglo = pt_tensor.numpy()\n",
    "\n",
    "print(np_areglo)\n",
    "\n",
    "pt_tensor[3] = 100\n",
    "\n",
    "print(np_areglo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas con tensores\n",
    "Sumar dos tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1782, 1.4035, 1.9314],\n",
       "        [1.5287, 1.3101, 1.6226],\n",
       "        [1.9442, 1.7406, 1.0712],\n",
       "        [1.3767, 1.8617, 1.3836],\n",
       "        [1.2778, 1.6913, 1.4779]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que pasa arriba es que creemos un nuevo tensor con valores del sumo entre `x` y `y`. Cuando estemos en un bucle sumando los dos tensores por ejemplo, lo de arriba será muy ineficiente por que estamos alocando memoria de un tensor nuevo cada vez.\n",
    "\n",
    "PyTorch nos permite definir explícito que queremos usar el tensor `z` para la salida, evitando alocar más memoria. Usemos `torch.add()` con el parámetros `out` que define donde guardar los resultados de la operación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y =\n",
      " tensor([[1.5051, 1.0503, 1.6637],\n",
      "        [1.4969, 1.0521, 1.5821],\n",
      "        [1.1165, 1.6013, 1.7955],\n",
      "        [1.9918, 1.6178, 1.0880],\n",
      "        [1.5296, 1.9169, 1.5099]])\n",
      "\n",
      "2x + y =\n",
      " tensor([[2.5051, 2.0503, 2.6637],\n",
      "        [2.4969, 2.0521, 2.5821],\n",
      "        [2.1165, 2.6013, 2.7955],\n",
      "        [2.9918, 2.6178, 2.0880],\n",
      "        [2.5296, 2.9169, 2.5099]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "z = torch.empty(5, 3)\n",
    "\n",
    "torch.add(x, y, out=z)\n",
    "print(\"x + y =\\n\", z)\n",
    "\n",
    "torch.add(x, z, out=z)\n",
    "print(\"\\n2x + y =\\n\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cambiar tamaño\n",
    "Cambiar el tamaño del tensor usando `torch.view()`. Si tenemos un tensor con tamaño `(4,4)`, podemos cambiar la 'vista' al tensor y cambiar su tamaño. Dando un tamaño `-1` para una dimensión automaticamente usa el valor que es válido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.4235e-01,  8.2155e-01,  2.6053e+00, -1.2334e+00],\n",
       "        [ 5.1302e-04, -9.4395e-01, -2.4674e-01, -1.4677e+00],\n",
       "        [-4.1857e-01, -5.5607e-02, -2.5504e-01,  4.8656e-01],\n",
       "        [-1.8836e-01,  3.4769e-01,  9.6786e-01,  1.1124e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(4, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4235e-01,  8.2155e-01,  2.6053e+00, -1.2334e+00,  5.1302e-04,\n",
       "        -9.4395e-01, -2.4674e-01, -1.4677e+00, -4.1857e-01, -5.5607e-02,\n",
       "        -2.5504e-01,  4.8656e-01, -1.8836e-01,  3.4769e-01,  9.6786e-01,\n",
       "         1.1124e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.4235e-01,  8.2155e-01],\n",
       "        [ 2.6053e+00, -1.2334e+00],\n",
       "        [ 5.1302e-04, -9.4395e-01],\n",
       "        [-2.4674e-01, -1.4677e+00],\n",
       "        [-4.1857e-01, -5.5607e-02],\n",
       "        [-2.5504e-01,  4.8656e-01],\n",
       "        [-1.8836e-01,  3.4769e-01],\n",
       "        [ 9.6786e-01,  1.1124e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.4235e-01,  8.2155e-01],\n",
       "        [ 2.6053e+00, -1.2334e+00],\n",
       "        [ 5.1302e-04, -9.4395e-01],\n",
       "        [-2.4674e-01, -1.4677e+00],\n",
       "        [-4.1857e-01, -5.5607e-02],\n",
       "        [-2.5504e-01,  4.8656e-01],\n",
       "        [-1.8836e-01,  3.4769e-01],\n",
       "        [ 9.6786e-01,  1.1124e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(8, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4235e-01,  8.2155e-01],\n",
       "         [ 2.6053e+00, -1.2334e+00]],\n",
       "\n",
       "        [[ 5.1302e-04, -9.4395e-01],\n",
       "         [-2.4674e-01, -1.4677e+00]],\n",
       "\n",
       "        [[-4.1857e-01, -5.5607e-02],\n",
       "         [-2.5504e-01,  4.8656e-01]],\n",
       "\n",
       "        [[-1.8836e-01,  3.4769e-01],\n",
       "         [ 9.6786e-01,  1.1124e+00]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(4, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplicaciones\n",
    "Por cada valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 24, 18])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([4, 3, 9])\n",
    "b = torch.tensor([1, 8, 2])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product entre dos vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(a, b) # a^T b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer product entre vectores da una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 32,  8],\n",
       "        [ 3, 24,  6],\n",
       "        [ 9, 72, 18]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ger(a, b) # a b^T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre un vector y una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 16.,  13., -97.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor([[2.0, 0.5], [1.0, -1.0], [-9.0, 4.0]])\n",
    "v = torch.tensor([9.0, -4.0])\n",
    "torch.mv(m, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre dos matrizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4544, 0.9667, 0.2806, 0.4770],\n",
       "        [0.8022, 1.4211, 0.5585, 0.7921],\n",
       "        [0.6241, 1.3195, 0.7368, 0.6820],\n",
       "        [0.5082, 0.6786, 0.1941, 0.4461],\n",
       "        [0.7949, 0.9010, 0.6169, 0.6922]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.rand(5, 3)\n",
    "m2 = torch.rand(3, 4)\n",
    "m3 = torch.mm(m1, m2) # tamaño 5x4\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4544, 1.4211, 0.7368, 0.4461])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "El package the `Autograd` permite diferenciación automática para todas las operaciones con tensores. Especialmente util al realizar _Backpropagation_ en las redes neuronales.\n",
    "\n",
    "Para activarlo, al crear un tensor se debe fijar el atributo `.requires_grad` como `True` guarda todas las operaciones en dicho tensor, cuando terminas de realizar calculos (Por ejemplo aplicar capas de una red) se puede llamar a `.backward()` y tener todos los gradientes calculados automáticamente. Donde el gradiente del tensor queda acumulado en el atributo `.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 0],[0, 1]], dtype=torch.float, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operamos sobre el tensor y veamos si guardas las operaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2.],\n",
       "        [2., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 12.],\n",
       "        [12., 27.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.5000, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = z.mean()\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradientes\n",
    "Tenemos $out = \\frac{1}{4}\\sum_i 3(x_i + 2)^2$, thus $\\frac{\\delta (out)}{\\delta x} = \\frac{3}{2}(x_i+2)$. La función `grad` evalua el gradiente en $x$:\n",
    "\n",
    "$$\\frac{\\delta (out)}{\\delta x_i} \\bigg\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$\n",
    "\n",
    "Como out es una función escalar, el gradiente va a ser una matriz de $2 \\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward() # calculamos el gradiente por defecto en gradient tensor([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 3.0000],\n",
       "        [3.0000, 4.5000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, `backward` es la manera de calcular el gradiente desde ponemos `requires_grad=True`.\n",
    "\n",
    "Si tenemos una función $f(x) \\in \\mathbb{R}^m$ y un input $x \\in \\mathbb{R}^p$, luego el gradiente de $f$ respecto a $x$ es una matriz Jacobiana de $p \\times m$.\n",
    "\n",
    "Autograd fue construido para poder computar un producto vector-jacobiano, es decir, dado una matriz Jacobiana $J=\\frac{d y}{d x}$ y un vector cualquiera $v$ computa el producto $v^T \\cdot J$.\n",
    "\n",
    "Si $v$ es el gradiente de una función escalar $v = \\frac{d (g)}{d y}$ entonces podemos escribir el producto vector-jacobiano por la regla de la cadena.\n",
    "\n",
    "$$ J^T \\cdot v = \\frac{d g}{dx}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  625.3434, -1135.4089,  -128.4195], grad_fn=<MulBackward0>)\n",
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)\n",
    "\n",
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de modelo no lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Airline dataset')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt('passenger_data.txt')\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "r = 0.8 #training vesus all ratio\n",
    "til_train = int(len(y)*r)\n",
    "#x = x-til_train\n",
    "\n",
    "z = 10 * np.sin(x*0.51) * np.exp(x*0.02) + 100 + x*2.49\n",
    "\n",
    "x_trn = x[:int(len(y)*r)]\n",
    "y_trn = y[:int(len(y)*r)]\n",
    "\n",
    "x_tst = x[int(len(y)*r):]\n",
    "y_tst = y[int(len(y)*r):]\n",
    "print(y.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(x_tst,y_tst, 'or')\n",
    "plt.plot(x_trn,y_trn, 'og')\n",
    "plt.title('Airline dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo_nolineal()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class modelo_nolineal(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(modelo_nolineal, self).__init__()\n",
    "        #self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        #self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        #self.c = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        #self.d = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        #self.e = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        #self.f = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.a = nn.Parameter(torch.tensor([100], dtype=torch.float, requires_grad=True))\n",
    "        self.b = nn.Parameter(torch.tensor([2], dtype=torch.float, requires_grad=True))\n",
    "        self.c = nn.Parameter(torch.tensor([10], dtype=torch.float, requires_grad=True))\n",
    "        self.d = nn.Parameter(torch.tensor([1], dtype=torch.float, requires_grad=True))\n",
    "        self.e = nn.Parameter(torch.tensor([0.01], dtype=torch.float, requires_grad=True))\n",
    "        self.f = nn.Parameter(torch.tensor([0], dtype=torch.float, requires_grad=True))\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #return self.a + self.b * x\n",
    "        bias = self.a\n",
    "        slope = self.b\n",
    "        growth = self.c * torch.exp(self.d * x)\n",
    "        oscillatory = torch.cos(2*np.pi* x/12 + self.f)\n",
    "        return bias + slope * x + growth * oscillatory\n",
    "        #return self.a + self.b*x + self.c*x**2 \n",
    "\n",
    "\n",
    "modelo = modelo_nolineal()\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo_NN(\n",
      "  (fc1): Linear(in_features=1, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=240, bias=True)\n",
      "  (fc3): Linear(in_features=240, out_features=200, bias=True)\n",
      "  (fc4): Linear(in_features=200, out_features=150, bias=True)\n",
      "  (fc5): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc6): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc7): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class modelo_NN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(modelo_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 120)  \n",
    "        self.fc2 = nn.Linear(120, 240)\n",
    "        self.fc3 = nn.Linear(240, 200)\n",
    "        self.fc4 = nn.Linear(200, 150)\n",
    "        self.fc5 = nn.Linear(150, 100)\n",
    "        self.fc6 = nn.Linear(100, 50)\n",
    "        self.fc7 = nn.Linear(50, 1)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "modelo = modelo_NN()\n",
    "print(modelo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capas: 14\n",
      "Tamaño de parámetro 1 => torch.Size([120, 1])\n",
      "Tamaño de parámetro 2 => torch.Size([120])\n",
      "Tamaño de parámetro 3 => torch.Size([240, 120])\n",
      "Tamaño de parámetro 4 => torch.Size([240])\n",
      "Tamaño de parámetro 5 => torch.Size([200, 240])\n",
      "Tamaño de parámetro 6 => torch.Size([200])\n",
      "Tamaño de parámetro 7 => torch.Size([150, 200])\n",
      "Tamaño de parámetro 8 => torch.Size([150])\n",
      "Tamaño de parámetro 9 => torch.Size([100, 150])\n",
      "Tamaño de parámetro 10 => torch.Size([100])\n",
      "Tamaño de parámetro 11 => torch.Size([50, 100])\n",
      "Tamaño de parámetro 12 => torch.Size([50])\n",
      "Tamaño de parámetro 13 => torch.Size([1, 50])\n",
      "Tamaño de parámetro 14 => torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "params = list(modelo.parameters())\n",
    "print(\"Capas:\", len(params))\n",
    "for i, param in enumerate(params):\n",
    "    print(\"Tamaño de parámetro\", i+1, \"=>\", param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de perdida\n",
    "Una función de perdida toma una salida y el objetivo de su valor para calcular una medida de error. Por ejemplo, el `nn.MSELoss` que calcula el error de escuadrados mínimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0304], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1)\n",
    "out = modelo(input)\n",
    "print(out)  # tensor con tamaño 1x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1640, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = modelo(input)\n",
    "target = torch.randn(1)  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos propagación hacia atrás para empotrar los valores de error en nuestros cadas de red neuronal. En PyTorch hacemos el \"backprop\" simplemente usando `backward()` en la salida de función de perdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.zero_grad()  # borrar los valores de antes de todos parámetros\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "#modelo.a.grad\n",
    "#net.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualizar los pesos\n",
    "El método más simple de actualizar los pesos es el \"Stochastic Gradient Descent (SGD)\". En PyTorch podemos usar el packete `torch.optim` que nos da implementaciones de varios tipos de reglas de actualizar (como SGD, Nesterov-SGD, Adam, RMSProp, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = modelo(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "tensor_x = torch.from_numpy(x_trn)\n",
    "tensor_y = torch.from_numpy(y_trn)\n",
    "\n",
    "dataset_tr = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "b_size = 30\n",
    "trainloader = utils.DataLoader(dataset_tr,batch_size=b_size) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-93936c96d8f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#outputs = modelo(inputs.float())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-93936c96d8f3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#outputs = modelo(inputs.float())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c078d0de7122>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "\n",
    "modelo = modelo_NN()\n",
    "\n",
    "optimizer = torch.optim.Adagrad(modelo.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        modelo.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = torch.tensor([modelo(ip) for ip in inputs])\n",
    "\n",
    "        #outputs = modelo(inputs.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        print(modelo.fc1.grad)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    #print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))\n",
    "    #print(running_loss)\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "prediction = [modelo(torch.tensor([x_trn[i]])) for i in range(115)]\n",
    "plt.plot(tensor_x.numpy(),prediction)\n",
    "#plt.plot(tensor_x.numpy(),tensor_y.numpy())\n",
    "plt.plot(x_tst,y_tst, 'or')\n",
    "plt.plot(x_trn,y_trn, 'og')\n",
    "plt.title('Airline dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2d1831fcd0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhola\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c078d0de7122>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm"
     ]
    }
   ],
   "source": [
    "hola = inputs[1]\n",
    "print(inputs.shape)\n",
    "inp = torch.tensor([hola]) \n",
    "out = modelo(inp)\n",
    "outputs = torch.tensor([out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Para definir una red en PyTorch en general se siguen los siguentes pasos.\n",
    "\n",
    "* Definir la red que tenga parámetros entrenables (pesos)\n",
    "* Iterar sobre el dataset de inputs\n",
    "* Procesas el input a través de la red\n",
    "* Calcular la función de perdida (loss)\n",
    "* Propagar los gradientes hacia los parametros de la red\n",
    "* Actualizar los pesos de la red siguiendo una regla, en general se usa gradiente decendiente.\n",
    "\n",
    "### Crear una red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(\"Capas:\", len(params))\n",
    "for i, param in enumerate(params):\n",
    "    print(\"Tamaño de parámetros de capa\", i+1, \"=>\", param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entregar una entrada aleatoria de tamaño 1x3x32x32. Es decir que un \"batch\" de un elemento, tres colores, altura 32 y ancho 32. Es `nn.Conv2d` acepta un tensor de quatro dimensiones de `nSamples x nChannels x Height x Width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 32, 32)\n",
    "out = net(input)\n",
    "print(out)  # tensor con tamaño 1x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de perdida\n",
    "Una función de perdida toma una salida y el objetivo de su valor para calcular una medida de error. Por ejemplo, el `nn.MSELoss` que calcula el error de escuadrados mínimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos propagación hacia atrás para empotrar los valores de error en nuestros cadas de red neuronal. En PyTorch hacemos el \"backprop\" simplemente usando `backward()` en la salida de función de perdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()  # borrar los valores de antes de todos parámetros\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "net.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualizar los pesos\n",
    "El método más simple de actualizar los pesos es el \"Stochastic Gradient Descent (SGD)\". En PyTorch podemos usar el packete `torch.optim` que nos da implementaciones de varios tipos de reglas de actualizar (como SGD, Nesterov-SGD, Adam, RMSProp, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal ejemplo\n",
    "Vamos a usar `torchvision` para cargar un base de datos de imágenes. Instala con `conda install torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos unos imágenes que tenemos en el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elejamos una función criteria y de perdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './cifar_net.pth') # guardar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos cuatro imágenes aleatorios para ver si la red funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print images\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos la red y verifiquemos la salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tal funciona la red en los categorías?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "label_list = torch.zeros(0, dtype=torch.long)\n",
    "pred_list = torch.zeros(0, dtype=torch.long)\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        label_list = torch.cat([label_list, labels.view(-1)])\n",
    "        pred_list = torch.cat([pred_list, predicted.view(-1)])\n",
    "        \n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = confusion_matrix(label_list.numpy(), pred_list.numpy())\n",
    "df_cm = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sn.heatmap(df_cm, annot=True, cmap='rocket_r')\n",
    "\n",
    "b, t = plt.ylim()\n",
    "plt.ylim(b+0.5, t-0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entranar en el GPU\n",
    "Para verificar si tienes un GPU de Nvidia y has instalado CUDA (que es un método de acceder el GPU a través código), executamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar el red en el GPU (si lo de arriba dice `cuda:0`), tenemos que mudar todo los datos y la red hacia el GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
