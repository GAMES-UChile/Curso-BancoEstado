{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso BancoEstado-CMM: Aprendizaje de Máquinas Avanzado \n",
    "**Autores:** Taco de Wolff, Nicolas Caro y Felipe Tobar  \n",
    "\n",
    "**Fecha:** 27 deciembre, 2019\n",
    "\n",
    "# Módulo 9 - Redes Bayesianes\n",
    "Instalar con `conda install pomegranate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:51:16.493842Z",
     "start_time": "2019-12-23T15:51:15.787029Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set_style('whitegrid')\n",
    "import numpy as np\n",
    "\n",
    "from pomegranate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El eje central de este modulo se desarrolla en torno a los modelos gráficos\n",
    "probabilísticos (PGM). En términos generales, este tipo de modelo busca una\n",
    "representación compacta para distribuciones de probabilidad conjunta de la\n",
    "forma $p(\\mathbf{x} | \\mathbf{\\theta})$, valiéndose de los fundamentos matemáticos\n",
    "proporcionados por la teoría de grafos y de probabilidad.\n",
    "\n",
    "Los PGM son ampliamente utilizados en tareas de razonamiento bajo incertidumbre,\n",
    "tales como predicción, monitorio y diagnósticos médicos, además de tareas de\n",
    "estimación de riesgos y toma de decisiones.\n",
    "\n",
    "\n",
    "### Modelos gráficos dirigidos\n",
    "\n",
    "Toda distribución de probabilidad conjunta $p(\\mathbf{x} ) = p(x_1, x_2, \\ldots x_v)$  se puede\n",
    "representar de la forma:\n",
    "\\begin{equation}\n",
    "\t\\label{eq:regla_cadena}\n",
    "\tp(\\mathbf{x} ) = p(x_1)p(x_2 | x_1 )p(x_3 |  x_1, x_2) \\ldots p(x_v |  x_1, x_2, \\ldots , x_{v-1})\n",
    "\\end{equation}\n",
    "\n",
    "El problema con esta expresión es la dificultad computacional subyacente al cálculo de\n",
    "distribuciones condicionales de la forma $p(x_{t} |  x_1,\\ldots, x_{t-1} )$\n",
    "cuando el número de variables incidentes $t$ aumenta.\n",
    "\n",
    "En efecto, si se asume $x_{t+1} \\perp  x_{1}, \\ldots, x_{t-1} | x_t$. Es decir,\n",
    "las observaciones futuras $x_{t+1}$ son independientes del pasado $ x_{1}, \\ldots,\n",
    "x_{t-1}$, dado el estado presente $x_{t}$. La probabilidad conjunta se reduce entonces a:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:markov_prop}\n",
    "p(\\mathbf{x} ) = p(x_1) \\prod_{t = 2}^{v} p(x_t  |  x_1,\\ldots , x_{t-1}) = p(x_1) \\prod_{t = 2}^{v} p(x_t  | x_{t-1})\n",
    "\\end{equation}\n",
    "\n",
    "De lo cual se obtiene una expresión más simple.\n",
    "\n",
    "Modelar la independencia condicional entre las variables permite entonces reducir la\n",
    "complejidad de representación para la distribución conjunta. En particular, la elección anterior se conoce como **propiedad de\n",
    "Markov**.\n",
    "\n",
    "En un contexto general, las relaciones de independencia condicional entre variables aleatorias\n",
    "de dimensión arbitraria, se modelan utilizando **diagramas de independencia** o **modelos gráficos**. Estos se valen de un conjunto\n",
    "consistente de $\\mathcal{V} = \\lbrace{1 \\ldots , V} \\rbrace$ vértices (o nodos) y $\\mathcal{E} =\\lbrace {(s,t): s,t \\in \\mathcal{V}} \\rbrace$ aristas  para formar una estructura matemática conocida como **Grafo** $G=(\\mathcal{V}, \\mathcal{E})$.\n",
    "\n",
    "Los grafos permiten representar mediante nodos $v = 1, \\ldots, \\mathcal{V}$ las variables aleatorias del modelo,\n",
    "mientras que la presencia o ausencia de aristas entre estos nodos, permite teorizar sobre las relaciones de dependencia condicional entre variabes de un modelo.\n",
    "\n",
    "Una **red bayesiana** es un modelo gráfico probabilístico, cuyo grafo subyacente es un **grafo dirigido acíclico** (DAG). Todo DAG posee un **ordenamiento topológico**, es decir, los nodos de cualquier DAG pueden ser numerados de manera tal, que todo nodo padre posea una numeración inferior a sus nodos hijos. Esta característica permite enriquecer la formulación de la propiedad de Markov, usando la estructura gráfica como componente adicional, de\n",
    "esta forma, se puede reformular a una **propiedad ordenada de Markov** en modelos gráficos dirigidos:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{eq:Markov_ordenado}\n",
    "\tx_s \\perp  x_{pred(s) \\setminus pa(s)} ~ | ~  x_{pa(s)}\n",
    "\\end{equation}\n",
    "\n",
    "Es decir, un nodo $x_s$ es independiente de aquellos predecesores, menores en orden topológico,\n",
    "a sus padres $ x_{pred(s) \\setminus pa(s)}$, dados sus nodos padres $x_{pa(s)}$. De\n",
    "manera equivalente, un nodo $x_s$ solo depende de sus padres inmediatos $x_{pa(s)}$ y no de\n",
    "todos sus predecesores.\n",
    "\n",
    "De esta forma, la probabilidad conjunta de un modelo gráfico dirigido, que cumple la **propiedad\n",
    "ordenada de Markov**, se puede descomponer de la forma:\n",
    "\\begin{equation}\n",
    "\\label{eq:markov_prop_ord}\n",
    "p(\\mathbf{x} ) = \\prod_{t = 1}^{V} p(x_t  | x_{pa(t)})\n",
    "\\end{equation}\n",
    "\n",
    "Con el fin de explorar las posibilidades de este tipo de modelos e introducir conceptos\n",
    "referentes a la notación de estos, se pasan a estudiar los siguientes ejemplos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monty Hall\n",
    "\n",
    "Monty Hall fue un show de juegos en estados unidos, en el que se daba al concursante a elegir entre tres puertas, una de ellas permitía ganar auto como premio, las otras dos conducían a una cabra. Después elegir una puerta, el anfitrión abre una de las otras dos puertas en las que hay cabra, luego ofrece la oportunidad al concursante de cambiar su puerta previamente seleccionada. El problema consiste en encontrar una estrategia que maximice la probabilidad de ganar el auto.¿Conviene más cambiar de elección, mantener la elección o realmente no se ve afectada la probabilidad de ganar al cambiar de elección?\n",
    "\n",
    "Es intuitivo creer que al cambiar de puerta no se afecta la probabilidad de ganar, pero en realidad la estrategia ganadora corresponde a **siempre cambiar de puerta**. Con redes bayesianas es posible explorar este problema.\n",
    "\n",
    "El problema explicado en Wikipedia: https://en.wikipedia.org/wiki/Monty_Hall_problem\n",
    "\n",
    "### Interpretación probabilistica\n",
    "\n",
    "Supongamos que se tienen tres variables aleatorias: Concursante $ C \\in \\{1, 2, 3\\} $, Anfitrión $ H \\in \\{1, 2, 3\\} $ y el premio $ P \\in \\{1, 2, 3 \\} $. La probabilidad de que el premio esté detrás de una puerta aleatoria viene dada por $ P(P=1) = P(P=2) = P(P=3) = \\frac{1}{3} $. Además, el concursante seleccionará una puerta aleatoriamente, luego $ P(C=1) = P(C=2) = P(C=3) = \\frac{1}{3} $. Construimos una red Bayesiana así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:51:19.971361Z",
     "start_time": "2019-12-23T15:51:19.952642Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('monty.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:30:55.953206Z",
     "start_time": "2019-12-23T16:30:55.935416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Los concursantes eligen la puerta inicialmente aleatoriamente\n",
    "guest = DiscreteDistribution({'A': 1./3, 'B': 1./3, 'C': 1./3})\n",
    "\n",
    "# La puerta con el premio es aleatorio\n",
    "prize = DiscreteDistribution({'A': 1./3, 'B': 1./3, 'C': 1./3})\n",
    "\n",
    "# El anfitrión depende del concursante y el premio \n",
    "'''\n",
    "La tabla de probabilidad condicional se construye con la siguiente \n",
    "estructura:\n",
    "\n",
    "E1 : primera elección\n",
    "P  : Posción del premio \n",
    "Eh : elección del host\n",
    "Pr : Probabilidad de elegir Eh dado E1 y P\n",
    "\n",
    "[E1, Prize, Eh, Pr]\n",
    "\n",
    "Donde Pr es la probabilidad de elegir Eh dadas las elecciones E1 y P.\n",
    "\n",
    "'''\n",
    "\n",
    "host = ConditionalProbabilityTable(\n",
    "        [[ 'A', 'A', 'A', 0.0 ],\n",
    "         [ 'A', 'A', 'B', 0.5 ],\n",
    "         [ 'A', 'A', 'C', 0.5 ],\n",
    "         [ 'A', 'B', 'A', 0.0 ],\n",
    "         [ 'A', 'B', 'B', 0.0 ],\n",
    "         [ 'A', 'B', 'C', 1.0 ],\n",
    "         [ 'A', 'C', 'A', 0.0 ],\n",
    "         [ 'A', 'C', 'B', 1.0 ],\n",
    "         [ 'A', 'C', 'C', 0.0 ],\n",
    "         [ 'B', 'A', 'A', 0.0 ],\n",
    "         [ 'B', 'A', 'B', 0.0 ],\n",
    "         [ 'B', 'A', 'C', 1.0 ],\n",
    "         [ 'B', 'B', 'A', 0.5 ],\n",
    "         [ 'B', 'B', 'B', 0.0 ],\n",
    "         [ 'B', 'B', 'C', 0.5 ],\n",
    "         [ 'B', 'C', 'A', 1.0 ],\n",
    "         [ 'B', 'C', 'B', 0.0 ],\n",
    "         [ 'B', 'C', 'C', 0.0 ],\n",
    "         [ 'C', 'A', 'A', 0.0 ],\n",
    "         [ 'C', 'A', 'B', 1.0 ],\n",
    "         [ 'C', 'A', 'C', 0.0 ],\n",
    "         [ 'C', 'B', 'A', 1.0 ],\n",
    "         [ 'C', 'B', 'B', 0.0 ],\n",
    "         [ 'C', 'B', 'C', 0.0 ],\n",
    "         [ 'C', 'C', 'A', 0.5 ],\n",
    "         [ 'C', 'C', 'B', 0.5 ],\n",
    "         [ 'C', 'C', 'C', 0.0 ]], [guest, prize])\n",
    "\n",
    "# Los estados contienen la distribution y un nombre\n",
    "s1 = State(guest, name=\"guest\")\n",
    "s2 = State(prize, name=\"prize\")\n",
    "s3 = State(host, name=\"host\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:30:59.054130Z",
     "start_time": "2019-12-23T16:30:59.036535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la red Bayesiana\n",
    "model = BayesianNetwork(\"Monty Hall Problem\")\n",
    "\n",
    "# Agregamos los estados (nodos de grafo) \n",
    "model.add_states(s1, s2, s3)\n",
    "\n",
    "# Agregamos las aristas entre los nodos. El segundo nodo depende del primero nodo.\n",
    "# El anfitrión depende del concursante y el premio\n",
    "model.add_edge(s1, s3)\n",
    "model.add_edge(s2, s3)\n",
    "\n",
    "# Construir el modelo\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular probabilidades\n",
    "Supongamos que el concursante elige puerta A, y el anfitrión muestra puerta C. ¿Qué es la probabilidad que el premio is detrás puerta A o B, y nos conviene cambiar a puerta B?\n",
    "\n",
    "Sí, la probabilidad que el auto es detrás puerta B es $\\frac{2}{3}$ mientras la probabilidad que el auto es detrás A queda con $\\frac{1}{3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:31:05.951145Z",
     "start_time": "2019-12-23T16:31:05.940546Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict_proba({'guest': 'A', 'host': 'C'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa si solo el anfitrión muestra puerta A aunque el concursante no elegió nada? Hay igual probabilidad que el auto es detrás B o C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:31:16.761925Z",
     "start_time": "2019-12-23T16:31:16.746404Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict_proba({'host': 'A'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Dado un problema de clasificación de vectores $\\mathbf{x} = (x_1, \\ldots , x_V)$ en $C$ clases. Es\n",
    "posible modelar las variables de decisión $x_t$ como condicionalmente independientes dada la\n",
    "categoría de clasificación:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{eq:cond_nb}\n",
    "\tx_i \\perp x_j ~| y =  c, ~~ i \\neq j\n",
    "\\end{equation}\n",
    "\n",
    "Si se usa este enfoque, se obtiene que la densidad condicional de clases toma la forma:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{eq:naive_bayes}\n",
    "\tp(\\mathbf{x} ~ | y = c) = \\prod_{t=1}^{V}p(x_t ~ | y = c)\n",
    "\\end{equation}\n",
    "\n",
    "Al parametrizar las distribuciones de densidad condicional, es posible obtener un modelo de\n",
    "clasificación conocido como **clasificador Naive Bayes**, por medio de este, es posible clasificar mediante:\n",
    "\n",
    "\\begin{equation}\n",
    "\tp(y = c | \\mathbf{x} = (x_1,\\ldots,x_V)) =\\frac{p(c)}{p(\\mathbf{x})}\\cdot\\prod_{t=1}^{V}p(x_t ~ | y = c)\n",
    "\\end{equation}\n",
    "\n",
    "La estructura de las relaciones de independencia inducidas por tal método. se pueden expresar según el siguiente grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('naive_bayes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Como se relaciona con el ejemplo de Monty Hall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se entrena un clasificador Naive Bayes. En este caso se tiene la altura, el peso, y el tamaño de los pies para clasificar si cierta persona es hombre o mujer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:34:01.806330Z",
     "start_time": "2019-12-23T16:34:01.795286Z"
    }
   },
   "outputs": [],
   "source": [
    "male = NormalDistribution.from_samples([1.75, 1.72, 1.67, 1.81, 1.76, 1.71])\n",
    "female = NormalDistribution.from_samples([1.62, 1.59, 1.54, 1.68, 1.60, 1.61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:34:18.154633Z",
     "start_time": "2019-12-23T16:34:17.832537Z"
    }
   },
   "outputs": [],
   "source": [
    "male.plot(n=100000, edgecolor='c', color='c', bins=50, label='Hombre')\n",
    "female.plot(n=100000, edgecolor='g', color='g', bins=50, label='Mujer')\n",
    "plt.legend(fontsize=14)\n",
    "plt.ylabel('n')\n",
    "plt.xlabel('Altura (m)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Hombre: distribución tiene mu = %4.2f m y sigma = %5.3f m\" % (male.parameters[0], male.parameters[1]))\n",
    "print(\"Mujer: distribución tiene mu = %4.2f m y sigma = %5.3f m\" % (female.parameters[0], female.parameters[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` contiene la altura, el peso, y el tamaño de los pies para 12 personas. `y` dice `0` para un hombre y `1` para una mujer. Entrenamos nuestro modelo de Bayes ingenuo y distribuciones Gaussianes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:35:16.546113Z",
     "start_time": "2019-12-23T16:35:16.536121Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [\n",
    "    [1.75, 70, 11],\n",
    "    [1.72, 82, 12],\n",
    "    [1.67, 95, 12],\n",
    "    [1.81, 105, 13],\n",
    "    [1.76, 85, 10],\n",
    "    [1.71, 72, 11],\n",
    "    [1.62, 55, 9],\n",
    "    [1.59, 64, 6],\n",
    "    [1.54, 59, 8],\n",
    "    [1.68, 68, 7],\n",
    "    [1.60, 75, 9],\n",
    "    [1.61, 62, 8],\n",
    "]\n",
    "y = [0,0,0,0,0,0,1,1,1,1,1,1]\n",
    "\n",
    "clf = NaiveBayes.from_samples(NormalDistribution, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:35:32.642143Z",
     "start_time": "2019-12-23T16:35:32.627599Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[1.85, 80, 12], [1.70, 105, 11], [1.675, 69, 10], [1.65, 70, 7], [1.60, 65, 8]])\n",
    "\n",
    "for sample, probability in zip(data, clf.predict_proba(data)):\n",
    "    print(\"[%5.3f m, %3.0f kg, %2.0f ft]: %9.5f%% de probabilidad Hombre y %9.5f%% de probabilidad Mujer\" % (sample[0], sample[1], sample[2], 100*probability[0], 100*probability[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:35:53.596764Z",
     "start_time": "2019-12-23T16:35:53.581430Z"
    }
   },
   "outputs": [],
   "source": [
    "for sample, result in zip(data, clf.predict(data)):\n",
    "    print(\"Persona con [%5.3f m, %3.0f kg, %2.0f ft] es %s.\" % (sample[0], sample[1], sample[2], \"Mujer\" if result else \"Hombre\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura de Redes Bayesianas\n",
    "\n",
    "La estructura de una red bayesiana contiene las relaciones de independencia condicional relativos a una probabilidad condicional. De esta forma, si $X,Y,Z$ son variables aleatorias es posbile poseer relaciones de dependecia de la forma:\n",
    "\n",
    "* Secuencial:  $X \\rightarrow Y \\rightarrow Z$\n",
    "* Divergente:  $X \\leftarrow Y \\rightarrow Z$\n",
    "* Convetgente: $X \\rightarrow  Y \\leftarrow Z$\n",
    "\n",
    "En los primeros 2 casos, $X$ y $Z$ son condicionalmente independientes dada $Y$. Sin embargo, en el tercer caso, se tiene el fenomeno conocido como *explaining away* el cual corresponde a tener 2 *causas* asociadas a una misma *consecuencia*, por lo tanto, al conocer el efecto de una de las causas y la consecuencia, se altera la certidumbre sobre la causa última. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:37:36.991194Z",
     "start_time": "2019-12-23T16:37:36.984329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo de red Bayesiana con estructura más Compleja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia en Redes Bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje en Redes Bayesianas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
